<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.361">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jean de Dieu Nyandwi">
<meta name="dcterms.date" content="2023-07-23">
<meta name="description" content="Welcome to a new research blog!">

<title>Deep Learning Revision - Introducing Deep Learning Revision Research Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../deeprev.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Deep Learning Revision - Introducing Deep Learning Revision Research Blog">
<meta property="og:description" content="Welcome to a new research blog!">
<meta property="og:image" content="./introducing-deep-rev.png">
<meta property="og:site-name" content="Deep Learning Revision">
<meta name="twitter:title" content="Deep Learning Revision - Introducing Deep Learning Revision Research Blog">
<meta name="twitter:description" content="Welcome to a new research blog!">
<meta name="twitter:image" content="./introducing-deep-rev.png">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Deep Learning Revision</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Introducing Deep Learning Revision Research Blog</h1>
                  <div>
        <div class="description">
          Welcome to a new research blog!
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">updates</div>
                <div class="quarto-category">research</div>
                <div class="quarto-category">deep learning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Jean de Dieu Nyandwi </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 23, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p><img src="./introducing-deep-rev.png" class="img-fluid"></p>
<p>Greetings,</p>
<p>I am delighted to introduce Deep Learning Revision research blog. The aim of Deep Learning Revision blog is to elucidate both fundamental principles and cutting-edge techniques in AI research.</p>
<p>AI research has experienced a Cambrian explosion in recent years. Since 2012 when <a href="https://papers.nips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html">AlexNet</a> showed significant performance on image recognition, deep learning has profoundly reshaped the field of AI. The period between 2010-2020 was especially ripe with innovations:</p>
<ul>
<li><p>Development of new models: The past decade has seen the emergence of revolutionary models such <a href="https://arxiv.org/abs/1706.03762">Transformer neural network</a>, which have changed the game by making it possible to learn from vast amounts of data in a way that was not previously possible.</p></li>
<li><p>Improved optimization techniques that have made the model training process more efficient and manageable.</p></li>
<li><p>Enhanced evaluation benchmarks: Evaluation metrics and benchmarks have also seen significant improvements. From standard datasets in image recognition (like <a href="https://www.image-net.org/index.php">ImageNet</a>) to benchmarks in natural language understanding (such as <a href="https://arxiv.org/abs/1804.07461">GLUE</a> and <a href="https://arxiv.org/abs/1905.00537">SuperGLUE</a>), these advancements have provided the community with standard platforms to test and compare the performance of various models and techniques across a wide range of tasks.</p></li>
</ul>
<p>We have seen models like Transformers taking over natural language processing(NLP), computer vision, and at the same time showing potential in complex problems such as in robotics, reinforncement learning, etc…It’s even unbelievable what happened in the last two years. For instance, we have witnessed AI systems that are capable of generating photorealistic images, transcribing speeches with high accuracy, understanding multiple modalities, and generating realistic texts. Let’s expand that and provide a few specific examples:</p>
<ul>
<li><p>Image generation is arguably one of the fields that have had massive breakthroughts in last two years. In 2017, at best, the images you could generate were 32x32 pixels filled up with too much blogs. Fast forward, in 2023, image generation systems have improved to the extent it’s hard to differentiate real and fake images, and in the future, it will be the same for videos as well, if not already. Examples of seminal works in image generation are <a href="https://openai.com/dall-e-2">DALLE•2</a>, <a href="https://arxiv.org/abs/2112.10752">Stable Diffusion</a>, <a href="https://imagen.research.google/">Imagen</a>, among others.</p></li>
<li><p>Text generation has had many breakthroughs as image generation in recent times. Large language models have taken the world by a storm. The biggest revolution has mostly been in natural language interfaces like ChatGPT and Google Bard. Natural language interfaces are powered by large language models pretrained on massive amount of text data. Example of large language models are <a href="https://arxiv.org/abs/2005.14165">GPT-3</a>, <a href="https://arxiv.org/abs/2303.08774">GPT-4</a>, <a href="https://arxiv.org/abs/2204.02311">PaLM</a>, <a href="https://blog.google/technology/ai/google-palm-2-ai-large-language-model/">PaLM-2</a>, <a href="https://arxiv.org/abs/2302.13971">LLaMA</a>, <a href="https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/">LLaMA2</a>, <a href="https://arxiv.org/abs/2203.15556">Chinchilla</a>, <a href="https://arxiv.org/abs/2211.05100">BLOOM</a>, among others.</p></li>
<li><p>Multimodal learning is another concrete example of recent advancements in deep learning. Designing single systems that can see and hear what’s around and respond accordingly is the holy grail of AI. Although there are still challenges, it is inaruagable that the AI research community has solved independent modalities to a large extent. Agents in real-world however must have the ability to learn from multiple modalities jointly. A challenge now is to design AI systems that can efficiently extract meaningful representations from different modalities without requiring modality-specific encodings. There has been many remarkable works in multimodal learning(most of them are surprisingly visual language models). Notable examples are <a href="https://arxiv.org/abs/2204.14198">Flamingo</a>, <a href="https://arxiv.org/abs/2205.06175">Gato</a>, <a href="https://arxiv.org/abs/2201.12086">BLIP</a>(and <a href="https://arxiv.org/abs/2301.12597">BLIP-2</a>), <a href="https://arxiv.org/abs/2209.06794">PaLI</a> and <a href="https://arxiv.org/abs/2305.18565">PaLI-X</a>, among others. With the advancements of visual recognition models and language models as <a href="https://evjang.com/2021/12/17/lang-generalization.html">generalization engine</a>, I expect to see massive breakthroughts in this area in the next months.</p></li>
<li><p>Robotics is another field that is yet to be influenced by deep learning. Robotic tasks typically require low-level engineering and there are so much potential if modern deep learning algorithms can take care of those low-level tasks by learning from massive amount of data. Robotics as a field poses many challenges, but there are many ongoing works around deep robot learning and this also the field that is going to shine in the next few years. Some notable works around deep robotic learning that was published recently are <a href="https://say-can.github.io/">SayCan</a>, <a href="https://robotics-transformer.github.io/">Robotic Transformer(RT-1)</a>, <a href="https://arxiv.org/abs/2210.03094">VIMA</a>, <a href="https://arxiv.org/abs/2306.11706">RoboCat</a>, among others.</p></li>
</ul>
<p>I see this blog as a little corner in the universe where we can discuss recent research, deconstruct papers, and really try to understand what’s going on. I plan to publish well-studied materials across foundational techniques and some emerging topics. This is new project and as with other new projects, I don’t have everything figured out. New articles will be released irregularily, some may take longer(I tend not to compromise quality for speed), and some other unprojected challenges. All in all, I am super excited for this research blog and I can’t wait to publish the first article in the next few days.</p>
<p>Until the first article!</p>
<p>Cheers!</p>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>